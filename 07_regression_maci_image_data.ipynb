{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6dd576-8665-4cba-be2f-f749db97308d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "user = os.getenv('USER')\n",
    "os.chdir(f'/scratch/cd82/{user}/notebooks')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09e1a96-4780-4fe8-9717-2b16a950a592",
   "metadata": {},
   "source": [
    "## Linear Regression - Multivariate Analysis of Congruent Images (MACI)\n",
    "This is a method of getting quantiative data from images. The input data is a set of phtographs that show a glass of water containing various known volums of water. We label the images and pre-process them using scalling and change from colour to greyscale, and use wavelet analysis, which is a method that extracts various directional frequency information. This data is then reduced further by summation along rows or columns of the image and this is used as predictors for the volume of water that the image represents.  \n",
    "\n",
    "As the many preprocessing options present a large array of possible options, we trial a Grid Search algorithm to help select the hyperparameters used to find a good model.\n",
    "\n",
    "Ref:  \n",
    "``` \"Multivariate Analysis of Congruent Images\" L. Eriksson, S. Wold, J. Trygg, 2006, Journal of Chemometrics```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3543ef7-6881-4707-b868-c5e418e6fd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c960eeb1-05f2-4bed-9ab0-7763a04ddc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3763e4-e61e-4a8d-aadc-e6e26c803ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pywt\n",
    "import glob\n",
    "import os\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "image_path = current_directory + '/data/'\n",
    "\n",
    "# Get the list of JPG files\n",
    "jpg_files = glob.glob(os.path.join(image_path, '*.JPG'))\n",
    "# Print the filenames\n",
    "# for file in jpg_files:\n",
    "#    print(os.path.basename(file))\n",
    "\n",
    "# Load the image\n",
    "image = Image.open(os.path.join(image_path,jpg_files[5]))\n",
    "\n",
    "# Get the original dimensions\n",
    "original_width, original_height = image.size\n",
    "\n",
    "# Calculate the aspect ratio\n",
    "aspect_ratio = original_width / original_height\n",
    "\n",
    "new_width = 128  # Example new width\n",
    "new_height = int(new_width / aspect_ratio)\n",
    "\n",
    "# Rescale the image\n",
    "new_size = (new_width, new_height)  # Example size\n",
    "\n",
    "print(f' new_width: {new_width},  new_height: {new_height}')\n",
    "\n",
    "\n",
    "rescaled_image = image.resize(new_size)\n",
    "\n",
    "# Convert the image to greyscale\n",
    "greyscale_image = rescaled_image.convert('L')\n",
    "\n",
    "# Display the original and processed images\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "axes[0].imshow(image)\n",
    "axes[0].set_title('Original Image')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(greyscale_image, cmap='gray')\n",
    "axes[1].set_title('Greyscale Image')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Sample 2D data (e.g., an image)\n",
    "# Convert the image to a 2D NumPy array\n",
    "image_array = np.array(greyscale_image)\n",
    "print(\"Datatype of the image array:\", image_array.dtype)\n",
    "\n",
    "# Perform 2D Discrete Wavelet Transform\n",
    "coeffs2 = pywt.dwt2(image_array, 'db1')\n",
    "cA, (cH, cV, cD) = coeffs2\n",
    "\n",
    "print(\"Datatype of the cA:\", type(cA))\n",
    "print(\"Datatype of the cA array:\", cA.shape)\n",
    "print(\"Datatype of the cA array:\", cA.dtype)\n",
    "\n",
    "\n",
    "# Display the results\n",
    "fig, axes = plt.subplots(1, 4, figsize=(new_width, new_height))\n",
    "axes[0].imshow(cA, interpolation='nearest', cmap=plt.cm.gray)\n",
    "axes[0].set_title('Approximation coefficients')\n",
    "axes[0].axis('off')\n",
    "axes[1].imshow(cH, interpolation='nearest', cmap=plt.cm.gray)\n",
    "axes[1].set_title('Horizontal detail coefficients')\n",
    "axes[1].axis('off')\n",
    "axes[2].imshow(cV, interpolation='nearest', cmap=plt.cm.gray)\n",
    "axes[2].set_title('Vertical detail coefficients')\n",
    "axes[2].axis('off')\n",
    "axes[3].imshow(cD, interpolation='nearest', cmap=plt.cm.gray)\n",
    "axes[3].set_title('Diagonal detail coefficients')\n",
    "axes[3].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "image.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ea2b55-c134-4b60-b4aa-69199d49ad62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A helper function to pre-process a list of image files.\n",
    "def get_coeffs(image_path: str, images_filenames: list, key : str='cA', new_width: int=64, output: bool=False, ave_axis:int=0):\n",
    "    '''ave_axis default 0 is down columns, 1 is along rows '''\n",
    "    \n",
    "    coeff_list = list()\n",
    "    if output:\n",
    "        print(f'Processing {len( images_filenames )} files')\n",
    "        print(f'Selecting coefficients : {key}' )\n",
    "    for file in images_filenames:\n",
    "        if output:\n",
    "            print('Processing file: ',file )\n",
    "        # Load the image\n",
    "        image = Image.open(os.path.join(image_path,file))\n",
    "        \n",
    "        # Get the original dimensions\n",
    "        original_width, original_height = image.size\n",
    "        \n",
    "        # Calculate the aspect ratio\n",
    "        aspect_ratio = original_width / original_height\n",
    "        \n",
    "        # new_width = 128  # Example new width\n",
    "        new_height = int(new_width / aspect_ratio)\n",
    "        \n",
    "        # Rescale the image\n",
    "        new_size = (new_width, new_height) \n",
    "        \n",
    "        rescaled_image = image.resize(new_size)\n",
    "        \n",
    "        # Convert the image to greyscale\n",
    "        greyscale_image = rescaled_image.convert('L')\n",
    "        \n",
    "        # Convert the image to a 2D NumPy array\n",
    "        image_array = np.array(greyscale_image)\n",
    "        if output:\n",
    "            print('Perform 2D Discrete Wavelet : ',file )\n",
    "        # Perform 2D Discrete Wavelet Transform\n",
    "        coeffs2 = pywt.dwt2(image_array, 'db1')\n",
    "        cA, (cH, cV, cD) = coeffs2\n",
    "\n",
    "        bw_image_scaled = greyscale_image.resize(cA.shape)  # \n",
    "        dict_select = {'cA':cA, 'cH':cH, 'cV':cV, 'cD':cD, 'bw':bw_image_scaled }\n",
    "\n",
    "        if ave_axis < 2:\n",
    "            selectcoef = dict_select[key]\n",
    "            ave_coef = np.mean(selectcoef,axis=ave_axis)\n",
    "        else:\n",
    "            ave_coef = dict_select[key]\n",
    "              \n",
    "        coeff_list.append(ave_coef) \n",
    "        image.close()\n",
    "    return coeff_list\n",
    "\n",
    "def list_to_flat_np(list_of_arrays: list):\n",
    "    # Flatten each 2D array into a 1D array\n",
    "    flattened_arrays = [arr.flatten() for arr in list_of_arrays]\n",
    "    \n",
    "    # Convert the list of 1D arrays into a single 2D NumPy array\n",
    "    result_array = np.array(flattened_arrays)\n",
    "    \n",
    "    return result_array   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a285c07-2959-45b5-ab79-cb4f0b84f405",
   "metadata": {},
   "source": [
    "### Create a ```statsmodel``` OLS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88d5366-1ea5-475f-ac62-5680c3e97362",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "current_directory = os.getcwd()\n",
    "image_path = current_directory + '/data/'\n",
    "\n",
    "# image data filenames (order must match the y data values below)\n",
    "i1 = ['000_ml.JPG','025_ml.JPG','050_ml.JPG','075_ml.JPG', '100_ml.JPG','125_ml.JPG',\n",
    "      '150_ml.JPG','175_ml.JPG', '200_ml.JPG', '225_ml.JPG', '250_ml.JPG','275_ml.JPG',\n",
    "      '300_ml.JPG','325_ml.JPG', '350_ml.JPG', '375_ml.JPG', '400_ml.JPG']\n",
    "images_filenames = i1 \n",
    "\n",
    "# print('Training images: ' ,images_filenames)\n",
    "y=np.array([0.0, 0.025, 0.05, 0.075,0.10,0.125, 0.150,0.175, 0.20,0.225,0.25,0.275,0.30,0.325,0.35,0.375,0.40])\n",
    "y = y * 1000.0\n",
    "\n",
    "image_path_test = image_path\n",
    "image_test_filenames = ['245_ml.JPG','246_ml.JPG','111_ml.JPG','033_ml.JPG']\n",
    "y_test=np.array([0.245,0.245,0.111,0.033])\n",
    "y_test = y_test * 1000.0\n",
    "\n",
    "# This is the data setup for pre-processingthe images\n",
    "# Options for coefs: 'cA', 'cH', 'cV', 'cD', 'bw'\n",
    "# current options: \n",
    "params = { \n",
    "    'elastic_pc' : 1.0,\n",
    "    'alpha':15,\n",
    "    'im_size' : 128,\n",
    "    'coefs':'cV',\n",
    "    'axis' : 1\n",
    "}\n",
    "output=False\n",
    "\n",
    "# Get our preprocessed image data\n",
    "X_list_train = get_coeffs(image_path, images_filenames, params['coefs'], params['im_size'], output, params['axis'])\n",
    "X_list_test = get_coeffs(image_path_test, image_test_filenames,  params['coefs'], params['im_size'], output, params['axis'])\n",
    "\n",
    "# Convert the list of preprocessed images into a NumPy array\n",
    "X_train=list_to_flat_np(X_list_train)\n",
    "# Add an intercept\n",
    "X_train_intercept = sm.add_constant(X_train)\n",
    "\n",
    "X_test=list_to_flat_np(X_list_test)\n",
    "# Add an intercept\n",
    "X_test_intercept = sm.add_constant(X_test)\n",
    "\n",
    "# Display the matrix as an image\n",
    "plt.imshow(X_train, cmap='viridis')# You can choose different colormaps\n",
    "plt.colorbar()# Optional: Add a colorbar\n",
    "plt.title(\"Preprocessed Image data\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0885f7-f090-4d9c-bd5b-d52921c8e4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "ols_model = sm.OLS(y, X_train_intercept)\n",
    "\n",
    "results_sm = ols_model.fit()\n",
    "# Print the summary of the model\n",
    "print(results_sm.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da588237-2bb8-4d9c-bc39-89f90afbc7b6",
   "metadata": {},
   "source": [
    "---  \n",
    "What is seen above is that the results of the OLS fit are undefined.  \n",
    "The problem being that the image data has too many predictors for the number of samples in the dataset.\n",
    "We have a case to try a *regularised* model, where the model can remove predictor variables that do not contribute to the predictive power of the model.\n",
    "\n",
    "#### Creating a regularised model \n",
    "The Statsmodel package has an available *elastic net* implementation. We will try a Lasso model (L1 model), by forcing the *L1_wt* paramater to be 1.0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc88d51-d5e6-4603-bf0b-24b61ad7d317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the data setup for pre-processingthe images\n",
    "# Options for coefs: 'cA', 'cH', 'cV', 'cD', 'bw'\n",
    "# current options: \n",
    "params = { \n",
    "    'elastic_pc' : 1.0,\n",
    "    'alpha': 50.0,\n",
    "    'im_size' : 128,\n",
    "    'coefs':'cV',\n",
    "    'axis' : 1\n",
    "}\n",
    "# Stops extra information being printed in out preprocessing functions\n",
    "output=False\n",
    "\n",
    "# Get our preprocessed image data\n",
    "X_list_train = get_coeffs(image_path, images_filenames, params['coefs'], params['im_size'], output, params['axis'])\n",
    "X_list_test = get_coeffs(image_path_test, image_test_filenames,  params['coefs'], params['im_size'], output, params['axis'])\n",
    "\n",
    "# Convert the list of preprocessed images into a NumPy array\n",
    "X_train=list_to_flat_np(X_list_train)\n",
    "# Add an intercept\n",
    "X_train_intercept = sm.add_constant(X_train)\n",
    "\n",
    "X_test=list_to_flat_np(X_list_test)\n",
    "# Add an intercept\n",
    "X_test_intercept = sm.add_constant(X_test)\n",
    "\n",
    "\n",
    "# This is our new model\n",
    "lasso_model = sm.OLS(y, X_train_intercept).fit_regularized(method='elastic_net', \n",
    "                                                           alpha=params['alpha'], L1_wt=params['elastic_pc'])\n",
    "# Print the summary of the model\n",
    "non_zero_coefficients = np.sum(lasso_model.params != 0)\n",
    "print(f\"Number of non-zero coefficients: {non_zero_coefficients}\")\n",
    "\n",
    "# Make predictions\n",
    "y_test_pred = lasso_model.predict(X_test_intercept)\n",
    "print(\"Predictions:\", np.round(y_test_pred))\n",
    "print(\"Y test data:\", y_test)\n",
    "\n",
    "y_train_pred = lasso_model.predict(X_train_intercept)\n",
    "mse = mean_squared_error(y, y_train_pred)\n",
    "r2 = r2_score(y, y_train_pred)\n",
    "print(f\"R² Score (training): {r2}\")\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "r2 = r2_score(y_test, y_test_pred)\n",
    "print(f\"R² Score (test data): {r2}\")\n",
    "\n",
    "\n",
    "# Extract non-zero coefficients\n",
    "non_zero_indices = np.where(lasso_model.params != 0)[0]\n",
    "print('Retained parameters: ', non_zero_indices)\n",
    "\n",
    "highlights = np.zeros(lasso_model.params.shape) \n",
    "highlights[non_zero_indices] =  np.max(X_train_intercept)\n",
    "\n",
    "# Add a line on bottom of plot showing which pixels are important\n",
    "X_train_intercept_stack = np.vstack((X_train_intercept, highlights))\n",
    "\n",
    "# Display the matrix as an image\n",
    "plt.imshow(X_train_intercept_stack, cmap='viridis')# You can choose different colormaps\n",
    "plt.colorbar()# Optional: Add a colorbar\n",
    "plt.title(\"Preprocessed Image data\")\n",
    "plt.show()\n",
    "\n",
    "# Plot the scatter plot results\n",
    "plt.plot(y, y, color='red', linestyle='--', linewidth=0.5)  # Plot the regression line\n",
    "plt.scatter(y, y_train_pred, marker='x', color='green', s=10, label='Training prediction')\n",
    "plt.scatter(y_test, y_test_pred, marker='x', color='red', s=10, label='Test prediction')\n",
    "\n",
    "plt.xlabel('actual mL')\n",
    "plt.ylabel('predicted mL')\n",
    "plt.title('ElasticNet (alpha:' + str(params['alpha']) +' L1 % :' + str(params['elastic_pc']) + ')' )\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cee755-9ff8-43cb-9035-ad935856b9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# good data: \n",
    "good_params = { \n",
    "    'elastic_pc' : 1.0,\n",
    "    'alpha':15.0,\n",
    "    'im_size' : 128,\n",
    "    'coefs':'cV',\n",
    "    'axis' : 0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab50341-67f7-4007-a96b-de42aed56914",
   "metadata": {},
   "source": [
    "### Grid Search\n",
    "This code implements the GridSearchCV algorithm, which finds the best set of parameters for a model, using cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4e2d35-ee75-4f2b-8c13-42edcbfec9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "def custom_preprocessing(X, im_size, coefs, axis):\n",
    "    # The input X contains the Y values that were selected by the CV method\n",
    "    # So we have to load the X data that matches the y data (by filename match)\n",
    "    current_directory = os.getcwd()\n",
    "    image_path = current_directory + '/data/'\n",
    "\n",
    "    # image data filenames\n",
    "    # extras: '245_ml.JPG','246_ml.JPG','111_ml.JPG','033_ml.JPG'\n",
    "    i1 = ['000_ml.JPG','025_ml.JPG','050_ml.JPG','075_ml.JPG', '100_ml.JPG','125_ml.JPG',\n",
    "      '150_ml.JPG','175_ml.JPG', '200_ml.JPG', '225_ml.JPG', '250_ml.JPG','275_ml.JPG',\n",
    "      '300_ml.JPG','325_ml.JPG', '350_ml.JPG', '375_ml.JPG', '400_ml.JPG']\n",
    "    \n",
    "    Xdata = X.astype(int)\n",
    "    formatted_numbers = np.array([f'{num:03d}' for num in Xdata])\n",
    "    # ['000' '025' '050' ...\n",
    "\n",
    "    # These are the filenames needed\n",
    "    matched_files = [filename for filename in i1 if any(data_str in filename for data_str in formatted_numbers)]\n",
    "    \n",
    "    list_data = get_coeffs(image_path, matched_files, coefs, im_size, False, axis)\n",
    "    ret_X = list_to_flat_np(list_data)\n",
    "    ret_X_int = sm.add_constant(ret_X)\n",
    "    return ret_X_int\n",
    "\n",
    "\n",
    "preprocessor = FunctionTransformer(custom_preprocessing, kw_args={'im_size': 128, 'coefs': 'cV', 'axis': 0})\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', ElasticNet(max_iter=15000))\n",
    "])\n",
    "\n",
    "# This is the set of parameter combinations to test for\n",
    "# Notice that the names are prepended with the values in the \n",
    "# Pipeline definition above\n",
    "param_grid = {\n",
    "    'preprocessor__kw_args': [{'im_size': 256, 'coefs': 'cA', 'axis': 0},\n",
    "                             {'im_size': 128, 'coefs': 'cA', 'axis': 0},\n",
    "                             {'im_size': 64, 'coefs': 'cA', 'axis': 0},\n",
    "                             {'im_size': 256, 'coefs': 'cA', 'axis': 1},\n",
    "                             {'im_size': 128, 'coefs': 'cA', 'axis': 1},\n",
    "                             {'im_size': 64, 'coefs': 'cA', 'axis': 1},\n",
    "                             {'im_size': 256, 'coefs': 'cV', 'axis': 0},\n",
    "                             {'im_size': 128, 'coefs': 'cV', 'axis': 0},\n",
    "                             {'im_size': 64, 'coefs': 'cV', 'axis': 0},\n",
    "                             {'im_size': 256, 'coefs': 'cV', 'axis': 1},\n",
    "                             {'im_size': 128, 'coefs': 'cV', 'axis': 1},\n",
    "                             {'im_size': 64, 'coefs': 'cV', 'axis': 1},\n",
    "                             {'im_size': 256, 'coefs': 'cH', 'axis': 0},\n",
    "                             {'im_size': 128, 'coefs': 'cH', 'axis': 0},\n",
    "                             {'im_size': 64, 'coefs': 'cH', 'axis': 0},\n",
    "                             {'im_size': 256, 'coefs': 'cH', 'axis': 1},\n",
    "                             {'im_size': 128, 'coefs': 'cH', 'axis': 1},\n",
    "                             {'im_size': 64, 'coefs': 'cH', 'axis': 1},\n",
    "                             {'im_size': 256, 'coefs': 'cD', 'axis': 0},\n",
    "                             {'im_size': 128, 'coefs': 'cD', 'axis': 0},\n",
    "                             {'im_size': 64, 'coefs': 'cD', 'axis': 0},\n",
    "                             {'im_size': 256, 'coefs': 'cD', 'axis': 1},\n",
    "                             {'im_size': 128, 'coefs': 'cD', 'axis': 1},\n",
    "                             {'im_size': 64, 'coefs': 'cD', 'axis': 1},\n",
    "                             {'im_size': 256, 'coefs': 'bw', 'axis': 0},\n",
    "                             {'im_size': 128, 'coefs': 'bw', 'axis': 0},\n",
    "                             {'im_size': 64, 'coefs': 'bw', 'axis': 0},\n",
    "                             {'im_size': 256, 'coefs': 'bw', 'axis': 1},\n",
    "                             {'im_size': 128, 'coefs': 'bw', 'axis': 1},\n",
    "                             {'im_size': 64, 'coefs': 'bw', 'axis': 1}],\n",
    "                             \n",
    "    'model__alpha': [0.1, 0.5, 1.0, 10.0, 15.0, 50.0],\n",
    "    'model__l1_ratio': [1.0]\n",
    "}\n",
    "\n",
    "# y_test=np.array([0.245,0.246,0.111,0.033])\n",
    "# y_test = y_test * 1000.0\n",
    "# y = np.hstack((y, y_test))\n",
    "\n",
    "# Copy the exact y data as the X data. The values of the y data\n",
    "# are used as a lookup to the filenames to read in to form the X matrix\n",
    "X = np.copy(y) \n",
    "data = X.astype(int)\n",
    "formatted_numbers = np.array([f\"{num:03d}\" for num in data])\n",
    "print('formatted_numbers:',formatted_numbers)\n",
    "\n",
    "\n",
    "# The shuffle parameter is important if data has some internal structure\n",
    "# Our data is ordered smallest to largest, so this ordering can affect cross validation\n",
    "# results.\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "# kf = KFold(n_splits=5, shuffle=False)\n",
    "kf.get_n_splits(X)\n",
    "\n",
    "# Use the Grid search functionality of Scikit Learn\n",
    "# This function uses cross-validation to with 5-fold splitting of the data\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=kf , n_jobs=6, pre_dispatch='2*n_jobs', scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "best_model = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9586e6-b26e-4c7d-b61d-ddc1b12ca70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot the best paramters and see\n",
    "# current options: \n",
    "params = { \n",
    "    'elastic_pc' : 1.0,\n",
    "    'alpha': 1.0,\n",
    "    'im_size' : 256,\n",
    "    'coefs':'cV',\n",
    "    'axis' : 0\n",
    "}\n",
    "# Stops extra information being printed in out preprocessing functions\n",
    "output=False\n",
    "\n",
    "# Get our preprocessed image data\n",
    "X_list_train = get_coeffs(image_path, images_filenames, params['coefs'], params['im_size'], output, params['axis'])\n",
    "X_list_test = get_coeffs(image_path_test, image_test_filenames,  params['coefs'], params['im_size'], output, params['axis'])\n",
    "\n",
    "# Convert the list of preprocessed images into a NumPy array\n",
    "X_train=list_to_flat_np(X_list_train)\n",
    "# Add an intercept\n",
    "X_train_intercept = sm.add_constant(X_train)\n",
    "\n",
    "X_test=list_to_flat_np(X_list_test)\n",
    "# Add an intercept\n",
    "X_test_intercept = sm.add_constant(X_test)\n",
    "\n",
    "\n",
    "# This is our new model\n",
    "lasso_model = sm.OLS(y, X_train_intercept).fit_regularized(method='elastic_net', \n",
    "                                                           alpha=params['alpha'], L1_wt=params['elastic_pc'])\n",
    "# Print the summary of the model\n",
    "non_zero_coefficients = np.sum(lasso_model.params != 0)\n",
    "print(f\"Number of non-zero coefficients: {non_zero_coefficients}\")\n",
    "\n",
    "# Make predictions\n",
    "y_test_pred = lasso_model.predict(X_test_intercept)\n",
    "print(\"Predictions:\", np.round(y_test_pred))\n",
    "print(\"Y test data:\", y_test)\n",
    "\n",
    "y_train_pred = lasso_model.predict(X_train_intercept)\n",
    "mse = mean_squared_error(y, y_train_pred)\n",
    "r2 = r2_score(y, y_train_pred)\n",
    "print(f\"R² Score (training): {r2}\")\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "r2 = r2_score(y_test, y_test_pred)\n",
    "print(f\"R² Score (test data): {r2}\")\n",
    "\n",
    "\n",
    "# Extract non-zero coefficients\n",
    "non_zero_indices = np.where(lasso_model.params != 0)[0]\n",
    "print('Retained parameters: ', non_zero_indices)\n",
    "\n",
    "highlights = np.zeros(lasso_model.params.shape) \n",
    "highlights[non_zero_indices] =  np.max(X_train_intercept)\n",
    "\n",
    "# Add a line on bottom of plot showing which pixels are important\n",
    "X_train_intercept_stack = np.vstack((X_train_intercept, highlights))\n",
    "\n",
    "# Display the matrix as an image\n",
    "plt.imshow(X_train_intercept_stack, cmap='viridis')# You can choose different colormaps\n",
    "# plt.colorbar()# Optional: Add a colorbar\n",
    "plt.title(\"Preprocessed Image data\")\n",
    "plt.show()\n",
    "\n",
    "# Plot the scatter plot results\n",
    "plt.plot(y, y, color='red', linestyle='--', linewidth=0.5)  # Plot the regression line\n",
    "plt.scatter(y, y_train_pred, marker='x', color='green', s=10, label='Training prediction')\n",
    "plt.scatter(y_test, y_test_pred, marker='x', color='red', s=10, label='Test prediction')\n",
    "\n",
    "plt.xlabel('actual mL')\n",
    "plt.ylabel('predicted mL')\n",
    "plt.title('ElasticNet (alpha:' + str(params['alpha']) +' L1 % :' + str(params['elastic_pc']) + ')' )\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc3cf3a-5563-4524-a10a-202cde8fcfb2",
   "metadata": {},
   "source": [
    "---\n",
    "Our model as suggested by the Grid Search has produced a very good predition for our training data, however our (small) number of test images are not very well accounted for.  \n",
    "\n",
    "However, now we have a something close to optimal, we can  try a few more paramters for the Lasso model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329acb8e-a0f1-4e87-bc5c-6071107dfc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# current options: \n",
    "params = { \n",
    "    'elastic_pc' : 1.0,\n",
    "    'alpha': 15.0,\n",
    "    'im_size' : 128,\n",
    "    'coefs':'cV',\n",
    "    'axis' : 0\n",
    "}\n",
    "# Stops extra information being printed in out preprocessing functions\n",
    "output=False\n",
    "\n",
    "# Get our preprocessed image data\n",
    "X_list_train = get_coeffs(image_path, images_filenames, params['coefs'], params['im_size'], output, params['axis'])\n",
    "X_list_test = get_coeffs(image_path_test, image_test_filenames,  params['coefs'], params['im_size'], output, params['axis'])\n",
    "\n",
    "# Convert the list of preprocessed images into a NumPy array\n",
    "X_train=list_to_flat_np(X_list_train)\n",
    "# Add an intercept\n",
    "X_train_intercept = sm.add_constant(X_train)\n",
    "\n",
    "X_test=list_to_flat_np(X_list_test)\n",
    "# Add an intercept\n",
    "X_test_intercept = sm.add_constant(X_test)\n",
    "\n",
    "\n",
    "# This is our new model\n",
    "lasso_model = sm.OLS(y, X_train_intercept).fit_regularized(method='elastic_net', \n",
    "                                                           alpha=params['alpha'], L1_wt=params['elastic_pc'])\n",
    "# Print the summary of the model\n",
    "non_zero_coefficients = np.sum(lasso_model.params != 0)\n",
    "print(f\"Number of non-zero coefficients: {non_zero_coefficients}\")\n",
    "\n",
    "# Make predictions\n",
    "y_test_pred = lasso_model.predict(X_test_intercept)\n",
    "print(\"Predictions:\", np.round(y_test_pred))\n",
    "print(\"Y test data:\", y_test)\n",
    "\n",
    "y_train_pred = lasso_model.predict(X_train_intercept)\n",
    "mse = mean_squared_error(y, y_train_pred)\n",
    "r2 = r2_score(y, y_train_pred)\n",
    "print(f\"R² Score (training): {r2}\")\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "r2 = r2_score(y_test, y_test_pred)\n",
    "print(f\"R² Score (test data): {r2}\")\n",
    "\n",
    "\n",
    "# Extract non-zero coefficients\n",
    "non_zero_indices = np.where(lasso_model.params != 0)[0]\n",
    "print('Retained parameters: ', non_zero_indices)\n",
    "\n",
    "highlights = np.zeros(lasso_model.params.shape) \n",
    "highlights[non_zero_indices] =  np.max(X_train_intercept)\n",
    "\n",
    "# Add a line on bottom of plot showing which pixels are important\n",
    "X_train_intercept_stack = np.vstack((X_train_intercept, highlights))\n",
    "\n",
    "# Display the matrix as an image\n",
    "plt.imshow(X_train_intercept_stack, cmap='viridis')# You can choose different colormaps\n",
    "# plt.colorbar()# Optional: Add a colorbar\n",
    "plt.title(\"Preprocessed Image data\")\n",
    "plt.show()\n",
    "\n",
    "# Plot the scatter plot results\n",
    "plt.plot(y, y, color='red', linestyle='--', linewidth=0.5)  # Plot the regression line\n",
    "plt.scatter(y, y_train_pred, marker='x', color='green', s=10, label='Training prediction')\n",
    "plt.scatter(y_test, y_test_pred, marker='x', color='red', s=10, label='Test prediction')\n",
    "\n",
    "plt.xlabel('actual mL')\n",
    "plt.ylabel('predicted mL')\n",
    "plt.title('ElasticNet (alpha:' + str(params['alpha']) +' L1 % :' + str(params['elastic_pc']) + ')' )\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ded4e81-d521-4545-8bad-122540a0a35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "gs_results = grid_search.cv_results_\n",
    "grid_search_df = pd.DataFrame(gs_results)\n",
    "# print(grid_search_df.head())\n",
    "# Set option to display all rows\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "grid_search_df_sorted = grid_search_df.sort_values(by='rank_test_score', ascending=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f07304e-1a8e-4a97-a78d-7a129b5cb016",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, show\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.models import ColumnDataSource, HoverTool, FactorRange\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# 'mean_test_score',  'std_test_score',  'rank_test_score', 'param_preprocessor__kw_args', 'param_model__alpha',\n",
    "\n",
    "# Prepare data for Bokeh\n",
    "categories = ['mean_test_score',  'std_test_score']\n",
    "\n",
    "length = len(grid_search_df['mean_test_score'])\n",
    "print(\"Length of the 'mean_test_score' column:\", length)\n",
    "\n",
    "# Create a single row\n",
    "row = np.array([[0.5]])\n",
    "# Repeat the row to create a larger array\n",
    "array1 = np.tile(row, (length, 1))  \n",
    "\n",
    "# Create a single row\n",
    "row = np.array([[1.5]])\n",
    "# Repeat the row to create a larger array\n",
    "array2 = np.tile(row, (length, 1))  \n",
    "\n",
    "\n",
    "\n",
    "source = ColumnDataSource(data=dict(\n",
    "    cat1 = array1 ,\n",
    "    cat2 = array2 ,\n",
    "    mean_test_score = grid_search_df['mean_test_score'],\n",
    "    std_test_score = grid_search_df['std_test_score'],\n",
    "    rank=grid_search_df['rank_test_score'],\n",
    "    im_size=grid_search_df['param_preprocessor__kw_args'].apply(lambda x: x['im_size']),\n",
    "    coeffs=grid_search_df['param_preprocessor__kw_args'].apply(lambda x: x['coefs']),\n",
    "    axis=grid_search_df['param_preprocessor__kw_args'].apply(lambda x: x['axis']),\n",
    "    alpha=grid_search_df['param_model__alpha'],\n",
    "    \n",
    "))\n",
    "\n",
    "# Create a Bokeh figure\n",
    "p = figure(x_range=FactorRange(*categories),\n",
    "           height=400, width=600, title=\"Scores\" )\n",
    "\n",
    "# Add circles for scores and rank\n",
    "p.scatter(x='cat1', y='mean_test_score', size=10, source=source, color=\"navy\", alpha=0.5)\n",
    "p.scatter(x='cat2', y='std_test_score', size=10, source=source, color=\"navy\", alpha=0.5)\n",
    "\n",
    "\n",
    "# Add HoverTool for tooltips\n",
    "hover = HoverTool()\n",
    "hover.tooltips = [\n",
    "    (\"Rank\", \"@rank\"),\n",
    "    (\"size\", \"@im_size\"),\n",
    "    (\"coeffs\", \"@coeffs\"),\n",
    "    (\"axis\", \"@axis\"),\n",
    "    (\"alpha\", \"@alpha\")\n",
    "]\n",
    "p.add_tools(hover)\n",
    "\n",
    "# Add HoverTool for tooltips\n",
    "hover = HoverTool()\n",
    "hover.tooltips = [\n",
    "     (\"Rank, alpha,  im_size, coeff, axis\", \"@rank, @alpha,  @im_size, @coeffs, @axis\"),\n",
    " ]\n",
    "p.add_tools(hover)\n",
    "\n",
    "# Customize plot\n",
    "p.xgrid.grid_line_color = None\n",
    "# p.y_range.start = 0\n",
    "p.xaxis.axis_label = \"Category\"\n",
    "p.yaxis.axis_label = \"Value\"\n",
    "\n",
    "# Show the plot\n",
    "output_notebook()\n",
    "\n",
    "# Show the plot\n",
    "show(p) ;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf9b690-7300-4c10-baef-3f6b900eccef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv_cmdstan)",
   "language": "python",
   "name": "myenv_cmdstan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
