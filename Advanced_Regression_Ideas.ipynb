{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe7949dc-c3e9-466d-a845-2f346a2efa4b",
   "metadata": {},
   "source": [
    "\n",
    "## Multiple linear regression with Statsmodels\n",
    "\n",
    "### GLM modelling using statsmodels package:\n",
    "\n",
    "```\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sample data\n",
    "np.random.seed(0)\n",
    "data = pd.DataFrame({\n",
    "    'x1': np.random.normal(size=100),\n",
    "    'x2': np.random.normal(size=100),\n",
    "    'y': np.random.poisson(lam=2, size=100)\n",
    "})\n",
    "\n",
    "# Add a constant to the predictor variables\n",
    "data['const'] = 1\n",
    "\n",
    "# Define the GLM model\n",
    "model = sm.GLM(data['y'], data[['const', 'x1', 'x2']], family=sm.families.Poisson())\n",
    "\n",
    "# Fit the model\n",
    "results = model.fit()\n",
    "\n",
    "# Print the summary of the model\n",
    "print(results.summary())\n",
    "\n",
    "```\n",
    "\n",
    "### Time series modelling\n",
    "The statsmodels package has good GLM and timeseries modelling\n",
    "\n",
    "```\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv'\n",
    "data = pd.read_csv(url, parse_dates=['Month'], index_col='Month')\n",
    "\n",
    "# Plot the dataset\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(data)\n",
    "plt.title('Monthly International Airline Passengers')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Passengers')\n",
    "plt.show()\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "# Fit an ARMA model (ARIMA with no differencing)\n",
    "model = ARIMA(data, order=(2, 0, 2))\n",
    "model_fit = model.fit()\n",
    "\n",
    "# Summary of the model\n",
    "print(model_fit.summary())\n",
    "\n",
    "```\n",
    "The order parameter is set to (2, 0, 2), which means:\n",
    "\n",
    "p=2: The model includes the last two lagged values of the time series.\n",
    "d=0: The model does not use the first difference of the time series to make it stationary.\n",
    "q=2: The model includes the last two lagged forecast errors.\n",
    "\n",
    "```\n",
    "# Forecast the next 12 months\n",
    "forecast = model_fit.forecast(steps=12)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(data, label='Original')\n",
    "plt.plot(forecast, label='Forecast', color='red')\n",
    "plt.title('ARMA Model Forecast')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Passengers')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "### Mixed effects modelling\n",
    "y = Xbeta + Zu + error\n",
    "```\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data = pd.DataFrame({\n",
    "    'group': [1, 1, 2, 2, 3, 3],\n",
    "    'x': [1, 2, 3, 4, 5, 6],\n",
    "    'y': [2, 4, 6, 8, 10, 12]\n",
    "})\n",
    "\n",
    "model = smf.mixedlm(\"y ~ x\", data, groups=data[\"group\"])\n",
    "result = model.fit()\n",
    "print(result.summary())\n",
    "\n",
    "```\n",
    "\n",
    "### Logistics regression for image discrimination\n",
    "\n",
    "```\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Function to load images and convert them to grayscale\n",
    "def load_images_from_folder(folder, label):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder, filename))\n",
    "        if img is not None:\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            resized = cv2.resize(gray, (64, 64))  # Resize to 64x64\n",
    "            images.append(resized.flatten())  # Flatten the image\n",
    "            labels.append(label)\n",
    "    return images, labels\n",
    "\n",
    "# Load cat images\n",
    "cat_images, cat_labels = load_images_from_folder('path_to_cat_images', 0)\n",
    "\n",
    "# Load dog images\n",
    "dog_images, dog_labels = load_images_from_folder('path_to_dog_images', 1)\n",
    "\n",
    "# Combine the data\n",
    "X = np.array(cat_images + dog_images)\n",
    "y = np.array(cat_labels + dog_labels)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the logistic regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "### Reduced Major Axis (RMA) regression\n",
    "\n",
    "Reduced Major Axis (RMA) regression, also known as Geometric Mean Regression, \n",
    "is used when both Y and X have variations (i.e. X values are not known exactly)\n",
    "is not directly available in scikit-learn. However, you can implement it using \n",
    "numpy and scipy libraries. Here's an example:\n",
    "```\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Sample data\n",
    "np.random.seed(0)\n",
    "X = np.random.rand(100) * 10\n",
    "y = 2.5 * X + np.random.randn(100) * 2\n",
    "\n",
    "# Calculate the means\n",
    "X_mean = np.mean(X)\n",
    "y_mean = np.mean(y)\n",
    "\n",
    "# Calculate the standard deviations\n",
    "X_std = np.std(X)\n",
    "y_std = np.std(y)\n",
    "\n",
    "# Calculate the correlation coefficient\n",
    "r = np.corrcoef(X, y)[0, 1]\n",
    "\n",
    "# Calculate the slope and intercept for RMA\n",
    "slope = y_std / X_std * np.sign(r)\n",
    "intercept = y_mean - slope * X_mean\n",
    "\n",
    "# Predicted values\n",
    "y_pred = slope * X + intercept\n",
    "\n",
    "# Plotting\n",
    "plt.scatter(X, y, color='blue', alpha=0.5, label='Data')\n",
    "plt.plot(X, y_pred, color='red', label='RMA Regression Line')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### Reduced Major Axis (RMA) regression with multiple predictor variables:\n",
    "\n",
    "```\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Sample data\n",
    "np.random.seed(0)\n",
    "X1 = np.random.rand(100) * 10\n",
    "X2 = np.random.rand(100) * 5\n",
    "y = 2.5 * X1 + 1.5 * X2 + np.random.randn(100) * 2\n",
    "\n",
    "# Combine X1 and X2 into a single matrix\n",
    "X = np.vstack((X1, X2)).T\n",
    "\n",
    "# Calculate the means\n",
    "X_mean = np.mean(X, axis=0)\n",
    "y_mean = np.mean(y)\n",
    "\n",
    "# Calculate the standard deviations\n",
    "X_std = np.std(X, axis=0)\n",
    "y_std = np.std(y)\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "R = np.corrcoef(X.T, y)[:-1, -1]\n",
    "\n",
    "# Calculate the slopes for RMA\n",
    "slopes = y_std / X_std * np.sign(R)\n",
    "\n",
    "# Calculate the intercept\n",
    "intercept = y_mean - np.dot(slopes, X_mean)\n",
    "\n",
    "# Predicted values\n",
    "y_pred = np.dot(X, slopes) + intercept\n",
    "\n",
    "# Plotting\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(X1, X2, y, color='blue', alpha=0.5, label='Data')\n",
    "ax.plot_trisurf(X1, X2, y_pred, color='red', alpha=0.5, label='RMA Regression Plane')\n",
    "ax.set_xlabel('X1')\n",
    "ax.set_ylabel('X2')\n",
    "ax.set_zlabel('y')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "\n",
    "### Best subsets regression\n",
    "\n",
    "```\n",
    "pip install abess\n",
    "```\n",
    "Courtesy of Copilot:\n",
    "```\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from abess.linear import LinearRegression\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(0)\n",
    "X = np.random.randn(100, 10)\n",
    "beta = np.array([1.5, -2, 0, 0, 0, 3, 0, 0, 0, 0])\n",
    "y = X @ beta + np.random.randn(100) * 0.5\n",
    "\n",
    "# Fit the best subset selection model\n",
    "model = LinearRegression(support_size=3)  # support_size is the number of non-zero coefficients\n",
    "model.fit(X, y)\n",
    "\n",
    "# Get the selected features and coefficients\n",
    "selected_features = model.coef_ != 0\n",
    "print(\"Selected features:\", selected_features)\n",
    "print(\"Coefficients:\", model.coef_)\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Assuming y_true are the actual values and y_pred are the predicted values\n",
    "y_true = np.array([...])  # Replace with actual values\n",
    "y_pred = np.array([...])  # Replace with predicted values\n",
    "\n",
    "# Calculate metrics\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"R-squared (R^2):\", r2)\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "### Recording scalling factors of variables for later use in predisction\n",
    "\n",
    "Sklearn example of saving and using scale factors for normailisation of variables\n",
    "\n",
    "```\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# Simulated training data\n",
    "X_train = np.random.rand(100, 3)\n",
    "y_train = np.random.rand(100)\n",
    "\n",
    "# Initialize and fit the scaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Save the scaler\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "\n",
    "# Train a model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model, 'model.pkl')\n",
    "\n",
    "# Later, for prediction tasks\n",
    "# Load the scaler and model\n",
    "scaler = joblib.load('scaler.pkl')\n",
    "model = joblib.load('model.pkl')\n",
    "\n",
    "# Simulated new data\n",
    "X_new = np.random.rand(5, 3)\n",
    "\n",
    "# Scale the new data\n",
    "X_new_scaled = scaler.transform(X_new)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_new_scaled)\n",
    "print(predictions)\n",
    "\n",
    "```\n",
    "\n",
    "### Other scalers in ScikitLearn:\n",
    "\n",
    "```\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, MaxAbsScaler, QuantileTransformer, PowerTransformer\n",
    "\n",
    "# robust to outliers (median and interquartile range).\n",
    "scaler = RobustScaler() \n",
    "# Print the center (median) and scale (IQR)\n",
    "print(\"Center (Median):\", scaler.center_)\n",
    "print(\"Scale (IQR):\", scaler.scale_)\n",
    "\n",
    "# Scales features to a specified range, typically [0, 1]\n",
    "scaler = MinMaxScaler()\n",
    "# Print the data min and data max\n",
    "print(\"Data Min:\", scaler.data_min_)\n",
    "print(\"Data Max:\", scaler.data_max_)\n",
    "\n",
    "# Scales each feature by its maximum absolute value, preserving the sign\n",
    "scaler = MaxAbsScaler()\n",
    "print(\"Max Absolute Values:\", scaler.max_abs_)\n",
    "\n",
    "# Transforms features to follow a uniform or normal distribution.\n",
    "scaler = QuantileTransformer(output_distribution='normal')\n",
    "\n",
    "# Applies a power transformation to make data more Gaussian-like\n",
    "scaler = PowerTransformer(method='yeo-johnson')\n",
    "\n",
    "\n",
    "# Scale along samples(rows)\n",
    "from sklearn.preprocessing import Normalizer\n",
    "# each sample has unit norm (e.g., L2 norm).\n",
    "scaler = Normalizer()\n",
    "\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv_cmdstan)",
   "language": "python",
   "name": "myenv_cmdstan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
